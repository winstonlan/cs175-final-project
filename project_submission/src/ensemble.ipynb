{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "aApvxtKxRPwm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Code to read csv file into colaboratory:# Code  \n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#2. Get the file\n",
        "downloaded = drive.CreateFile({'id':'10Xf2Xv_pfnIycH2HpNZR3SwWHiHdrqzX'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('handwritten.csv')  \n",
        "\n",
        "#3. Read file as panda dataframe\n",
        "import pandas as pd\n",
        "data = pd.read_csv('handwritten.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wNge0YaORXfP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "!pip install -q numpy\n",
        "!pip install -q sklearn\n",
        "!pip install -q matplotlib\n",
        "!pip install -q pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9glOPQgnRYRU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZcbVL0YBRe2Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load the Data"
      ]
    },
    {
      "metadata": {
        "id": "Qmg3cqTvRgjd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "253979eb-690c-4bd5-98b2-20b5efaa7bf2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528823990301,
          "user_tz": 420,
          "elapsed": 27101,
          "user": {
            "displayName": "Winston Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104495917744035597997"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Get the data from the csv file\n",
        "data = data.values\n",
        "np.random.shuffle(data)\n",
        "\n",
        "# Split the data into X, Y, and parition the values into the training and test splits\n",
        "# Reshape X to be in the shape (N, 28, 28)\n",
        "X, Y = data[:,1:], data[:,0]\n",
        "# X = X.reshape(X.shape[0], 28, 28)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "print(\"Train {} {}\".format(X_train.shape, Y_train.shape))\n",
        "print(\"Test {} {}\".format(X_test.shape, Y_test.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train (297629, 784) (297629,)\n",
            "Test (74408, 784) (74408,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-JE3jBErRm9q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Prep"
      ]
    },
    {
      "metadata": {
        "id": "NwCbFYbQRlSO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1c68bc20-38d4-4603-e5d7-106feea61ea6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528823990699,
          "user_tz": 420,
          "elapsed": 334,
          "user": {
            "displayName": "Winston Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104495917744035597997"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "classes = np.unique(Y_train)\n",
        "n_classes = len(classes)\n",
        "print('Total number of outputs : ', n_classes)\n",
        "print('Output classes : ', classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of outputs :  26\n",
            "Output classes :  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pJXDA8nDjIau",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "img_size = 28\n",
        "img_size_flat = img_size * img_size\n",
        "img_shape = (img_size, img_size)\n",
        "\n",
        "classes = np.unique(Y_train)\n",
        "num_classes = len(classes)\n",
        "\n",
        "X_train = X_train.reshape(-1, img_size, img_size, 1)\n",
        "X_test = X_test.reshape(-1, img_size, img_size, 1)\n",
        "X_train = X_train.astype(\"float32\")\n",
        "X_test = X_test.astype(\"float32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7cAnZg7iRqkD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Normalization"
      ]
    },
    {
      "metadata": {
        "id": "0o5zJFqHRsY1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mean_image = np.mean(X_train, axis=0).astype(np.int64)\n",
        "X_train = (X_train - mean_image)/255\n",
        "X_test = (X_test - mean_image)/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EZumZB90RwQ4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5bf2e0b4-089e-467f-82f3-ca46d1ed8094",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528823994077,
          "user_tz": 420,
          "elapsed": 351,
          "user": {
            "displayName": "Winston Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104495917744035597997"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "Y_train_onehot = to_categorical(Y_train)\n",
        "Y_test_onehot = to_categorical(Y_test)\n",
        "print(\"Original Label: {}\".format(Y_train[0]))\n",
        "print(\"One Hot Label: {}\".format(Y_train_onehot[0]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Label: 2\n",
            "One Hot Label: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "CE4szLSER3bm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8894d4d3-4874-49a0-a7a6-28aeee0f0f25",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528823995114,
          "user_tz": 420,
          "elapsed": 906,
          "user": {
            "displayName": "Winston Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104495917744035597997"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train_onehot, test_size=0.2)\n",
        "\n",
        "print(\"Train: {} {}\".format(X_train.shape, Y_train.shape))\n",
        "print(\"Valid: {} {}\".format(X_valid.shape, Y_valid.shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: (238103, 28, 28, 1) (238103, 26)\n",
            "Valid: (59526, 28, 28, 1) (59526, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i2b7YAsidG-Y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "2b189a3c-eb99-4df5-fae1-cfc698ee2e74",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528823995827,
          "user_tz": 420,
          "elapsed": 671,
          "user": {
            "displayName": "Winston Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104495917744035597997"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_example1 = X_train[0]\n",
        "X_example2 = X_test[0]\n",
        "\n",
        "fig= plt.figure(figsize=(8,8))\n",
        "\n",
        "X_example1_2d = X_example1.reshape(28,28)\n",
        "fig.add_subplot(1,2,1)\n",
        "plt.imshow(X_example1_2d)\n",
        "plt.title(\"Ground Truth: {}\".format(Y_train[0]))\n",
        "\n",
        "X_example2_2d = X_example2.reshape(28,28)\n",
        "fig.add_subplot(1,2,2)\n",
        "plt.imshow(X_example2_2d)\n",
        "plt.title(\"Ground Truth: {}\".format(Y_test[0]))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAEHCAYAAACwZnznAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f38850d2f98>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "nYho84e7evEn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras Inits"
      ]
    },
    {
      "metadata": {
        "id": "_X_vsIL-ew0b",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.layers import LeakyReLU, ELU\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import InputLayer, Input\n",
        "from tensorflow.python.keras.layers import Reshape, MaxPooling2D\n",
        "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
        "from tensorflow.python.keras import initializers\n",
        "from tensorflow.python.keras.losses import mean_absolute_error\n",
        "\n",
        "\n",
        "#Add whatever you need here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1-twqHw3kGJm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.layers import BatchNormalization\n",
        "from tensorflow.python.keras.layers import Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e-krwZ9khFEO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Models"
      ]
    },
    {
      "metadata": {
        "id": "XftRrXHjdt6L",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 20\n",
        "num_classes = 26"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uJHUv_1ge9Bq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]"
      ]
    },
    {
      "metadata": {
        "id": "MNgdmXdxe-5y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model1():\n",
        "    model = Sequential()\n",
        "    '''\n",
        "    initializer: he_normal\n",
        "    A more recent paper on this topic, Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification by He et al., \n",
        "    derives an initialization specifically for ReLU neurons, reaching the conclusion that the variance of neurons \n",
        "    in the network should be 2.0/n. This gives the initialization w = np.random.randn(n) * sqrt(2.0/n), \n",
        "    and is the current recommendation for use in practice in the specific case of neural networks with ReLU neurons.\n",
        "    '''\n",
        "    #convolutional layer\n",
        "    model.add(Conv2D(kernel_size=7, strides=1, filters=16, padding='same',\n",
        "                     activation='linear', name='layer_conv1', input_shape=(img_size,img_size,1)))\n",
        "    #reLU activation\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    #Pooling Layer\n",
        "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    #Fully-Connected Layer with 128 outputs Adding this in improved scores\n",
        "    model.add(Dense(128, activation='linear'))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    #Fully-Connected Layer with Softmax\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    '''\n",
        "    For multiclass classification problems like MNIST, cross entropy is typically used as the loss metric\n",
        "    '''\n",
        "    model.compile(optimizer=Adam(lr=1e-3),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "# Insert model here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jXEGJeOzfB8o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]"
      ]
    },
    {
      "metadata": {
        "id": "YNidiKw6fGro",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model2():\n",
        "  optimizer = Adam(lr=1e-3)\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  #conv\n",
        "  #keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, \n",
        "      #dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', \n",
        "      #bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \n",
        "      #activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
        "  model.add(Conv2D(filters=16, kernel_size=8, strides = 1, padding='same', activation='linear',\n",
        "                   bias_initializer='zeros', input_shape=(img_size,img_size,1)))\n",
        "\n",
        "  #ReLu\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "  #conv2\n",
        "  model.add(Conv2D(filters=16, kernel_size=8, strides = 2, padding='same', activation='linear',\n",
        "                   bias_initializer='zeros', input_shape=(img_size,img_size,1)))\n",
        "\n",
        "  #ReLu\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "  #MaxPool\n",
        "  #keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)\n",
        "  model.add(MaxPooling2D(strides=2, padding='same'))\n",
        "\n",
        "  #Affine\n",
        "  model.add(Flatten())\n",
        "\n",
        "  #keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', \n",
        "      #bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \n",
        "      #activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
        "  #model.add(Dense(56, activation=\"relu\"))\n",
        "\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a13Nl1_pfLaO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]"
      ]
    },
    {
      "metadata": {
        "id": "aQoy4r-CfWPi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model3():\n",
        "  brc_model = Sequential()\n",
        "\n",
        "  brc_model.add(BatchNormalization(input_shape=(28, 28, 1)))\n",
        "  brc_model.add(Activation(\"relu\"))\n",
        "  brc_model.add(Conv2D(32, kernel_size=(5,5), activation=\"linear\", padding=\"same\"))\n",
        "\n",
        "  brc_model.add(BatchNormalization())\n",
        "  brc_model.add(Activation(\"relu\"))\n",
        "  brc_model.add(Conv2D(64, kernel_size=(5,5), activation=\"linear\", padding=\"same\"))\n",
        "\n",
        "  brc_model.add(Flatten())\n",
        "\n",
        "  brc_model.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "  brc_model.add(Dense(num_classes, activation='softmax'))\n",
        "  \n",
        "  brc_model.compile(optimizer=Adam(lr=1e-3),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  return brc_model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rJ6juMoVhLNr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "mbcpr6eknB0n",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "models = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pBziSjFammXN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1091
        },
        "outputId": "7893d3b9-c170-4a1c-8e76-6e4c1c15be7b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528824459488,
          "user_tz": 420,
          "elapsed": 453580,
          "user": {
            "displayName": "Winston Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104495917744035597997"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mod1 = model1()\n",
        "mod1.summary()\n",
        "mod1.fit(x=X_train,\n",
        "          y=Y_train,\n",
        "          epochs=epochs, batch_size=128,verbose=1, validation_data=(X_valid, Y_valid))\n",
        "models.append(mod1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer_conv1 (Conv2D)         (None, 28, 28, 16)        800       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               401536    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 26)                3354      \n",
            "=================================================================\n",
            "Total params: 405,690\n",
            "Trainable params: 405,690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 238103 samples, validate on 59526 samples\n",
            "Epoch 1/20\n",
            " 41728/238103 [====>.........................] - ETA: 33s - loss: 0.5586 - acc: 0.8459"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 26s 111us/step - loss: 0.2144 - acc: 0.9414 - val_loss: 0.0977 - val_acc: 0.9733\n",
            "Epoch 2/20\n",
            "202752/238103 [========================>.....] - ETA: 3s - loss: 0.0889 - acc: 0.9761"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 23s 95us/step - loss: 0.0876 - acc: 0.9764 - val_loss: 0.0828 - val_acc: 0.9772\n",
            "Epoch 3/20\n",
            "238103/238103 [==============================] - 22s 94us/step - loss: 0.0676 - acc: 0.9818 - val_loss: 0.0710 - val_acc: 0.9812\n",
            "Epoch 4/20\n",
            " 16640/238103 [=>............................] - ETA: 19s - loss: 0.0483 - acc: 0.9877"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 22s 94us/step - loss: 0.0555 - acc: 0.9849 - val_loss: 0.0639 - val_acc: 0.9836\n",
            "Epoch 5/20\n",
            "195072/238103 [=======================>......] - ETA: 3s - loss: 0.0472 - acc: 0.9867"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 22s 94us/step - loss: 0.0467 - acc: 0.9868 - val_loss: 0.0614 - val_acc: 0.9845\n",
            "Epoch 6/20\n",
            "238103/238103 [==============================] - 22s 93us/step - loss: 0.0392 - acc: 0.9890 - val_loss: 0.0592 - val_acc: 0.9846\n",
            "Epoch 7/20\n",
            " 15104/238103 [>.............................] - ETA: 20s - loss: 0.0315 - acc: 0.9918"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 22s 94us/step - loss: 0.0329 - acc: 0.9908 - val_loss: 0.0581 - val_acc: 0.9852\n",
            "Epoch 8/20\n",
            "194048/238103 [=======================>......] - ETA: 3s - loss: 0.0293 - acc: 0.9919"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 22s 94us/step - loss: 0.0294 - acc: 0.9919 - val_loss: 0.0564 - val_acc: 0.9862\n",
            "Epoch 9/20\n",
            "238103/238103 [==============================] - 23s 95us/step - loss: 0.0262 - acc: 0.9928 - val_loss: 0.0555 - val_acc: 0.9860\n",
            "Epoch 10/20\n",
            " 13440/238103 [>.............................] - ETA: 19s - loss: 0.0204 - acc: 0.9952"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 22s 94us/step - loss: 0.0231 - acc: 0.9935 - val_loss: 0.0573 - val_acc: 0.9872\n",
            "Epoch 11/20\n",
            "194048/238103 [=======================>......] - ETA: 3s - loss: 0.0198 - acc: 0.9947"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 23s 95us/step - loss: 0.0207 - acc: 0.9945 - val_loss: 0.0539 - val_acc: 0.9879\n",
            "Epoch 12/20\n",
            "238103/238103 [==============================] - 22s 94us/step - loss: 0.0185 - acc: 0.9950 - val_loss: 0.0553 - val_acc: 0.9880\n",
            "Epoch 13/20\n",
            " 14208/238103 [>.............................] - ETA: 19s - loss: 0.0161 - acc: 0.9955"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 22s 94us/step - loss: 0.0176 - acc: 0.9951 - val_loss: 0.0602 - val_acc: 0.9881\n",
            "Epoch 14/20\n",
            "193536/238103 [=======================>......] - ETA: 3s - loss: 0.0169 - acc: 0.9954"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 22s 94us/step - loss: 0.0170 - acc: 0.9954 - val_loss: 0.0594 - val_acc: 0.9885\n",
            "Epoch 15/20\n",
            "238103/238103 [==============================] - 23s 95us/step - loss: 0.0154 - acc: 0.9962 - val_loss: 0.0592 - val_acc: 0.9885\n",
            "Epoch 16/20\n",
            " 13568/238103 [>.............................] - ETA: 20s - loss: 0.0131 - acc: 0.9966"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 23s 95us/step - loss: 0.0146 - acc: 0.9961 - val_loss: 0.0561 - val_acc: 0.9892\n",
            "Epoch 17/20\n",
            "192896/238103 [=======================>......] - ETA: 3s - loss: 0.0131 - acc: 0.9966"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 22s 94us/step - loss: 0.0139 - acc: 0.9964 - val_loss: 0.0630 - val_acc: 0.9884\n",
            "Epoch 18/20\n",
            "238103/238103 [==============================] - 23s 95us/step - loss: 0.0134 - acc: 0.9966 - val_loss: 0.0648 - val_acc: 0.9885\n",
            "Epoch 19/20\n",
            " 13440/238103 [>.............................] - ETA: 19s - loss: 0.0101 - acc: 0.9974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 22s 93us/step - loss: 0.0135 - acc: 0.9966 - val_loss: 0.0625 - val_acc: 0.9894\n",
            "Epoch 20/20\n",
            "194944/238103 [=======================>......] - ETA: 3s - loss: 0.0120 - acc: 0.9972"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 22s 93us/step - loss: 0.0127 - acc: 0.9969 - val_loss: 0.0668 - val_acc: 0.9883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9lanntfjhOxR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1091
        },
        "outputId": "a5fbec67-6aab-46be-faaa-9a2f7fecc6b9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528825049086,
          "user_tz": 420,
          "elapsed": 589559,
          "user": {
            "displayName": "Winston Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104495917744035597997"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mod2 = model2()\n",
        "mod2.summary()\n",
        "mod2.fit(x=X_train,\n",
        "          y=Y_train,\n",
        "          epochs=epochs, batch_size=128,verbose=1, validation_data=(X_valid, Y_valid))\n",
        "models.append(mod2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 16)        1040      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 16)        16400     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 26)                20410     \n",
            "=================================================================\n",
            "Total params: 37,850\n",
            "Trainable params: 37,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 238103 samples, validate on 59526 samples\n",
            "Epoch 1/20\n",
            " 34560/238103 [===>..........................] - ETA: 24s - loss: 0.7261 - acc: 0.8013"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 30s 125us/step - loss: 0.2451 - acc: 0.9328 - val_loss: 0.1148 - val_acc: 0.9694\n",
            "Epoch 2/20\n",
            "146048/238103 [=================>............] - ETA: 10s - loss: 0.1037 - acc: 0.9725"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 123us/step - loss: 0.1011 - acc: 0.9733 - val_loss: 0.0930 - val_acc: 0.9752\n",
            "Epoch 3/20\n",
            "189056/238103 [======================>.......] - ETA: 5s - loss: 0.0827 - acc: 0.9781"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 123us/step - loss: 0.0820 - acc: 0.9782 - val_loss: 0.0784 - val_acc: 0.9791\n",
            "Epoch 4/20\n",
            "203264/238103 [========================>.....] - ETA: 4s - loss: 0.0691 - acc: 0.9817"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 124us/step - loss: 0.0702 - acc: 0.9815 - val_loss: 0.0708 - val_acc: 0.9816\n",
            "Epoch 5/20\n",
            "208768/238103 [=========================>....] - ETA: 3s - loss: 0.0631 - acc: 0.9833"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 30s 125us/step - loss: 0.0626 - acc: 0.9834 - val_loss: 0.0724 - val_acc: 0.9813\n",
            "Epoch 6/20\n",
            "210688/238103 [=========================>....] - ETA: 3s - loss: 0.0567 - acc: 0.9850"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 30s 124us/step - loss: 0.0565 - acc: 0.9850 - val_loss: 0.0670 - val_acc: 0.9827\n",
            "Epoch 7/20\n",
            "211968/238103 [=========================>....] - ETA: 3s - loss: 0.0514 - acc: 0.9863"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 124us/step - loss: 0.0519 - acc: 0.9861 - val_loss: 0.0652 - val_acc: 0.9834\n",
            "Epoch 8/20\n",
            "213760/238103 [=========================>....] - ETA: 2s - loss: 0.0472 - acc: 0.9875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 123us/step - loss: 0.0475 - acc: 0.9874 - val_loss: 0.0666 - val_acc: 0.9825\n",
            "Epoch 9/20\n",
            "213248/238103 [=========================>....] - ETA: 2s - loss: 0.0442 - acc: 0.9880"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 124us/step - loss: 0.0438 - acc: 0.9881 - val_loss: 0.0649 - val_acc: 0.9839\n",
            "Epoch 10/20\n",
            "212096/238103 [=========================>....] - ETA: 2s - loss: 0.0409 - acc: 0.9891"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 30s 124us/step - loss: 0.0414 - acc: 0.9888 - val_loss: 0.0639 - val_acc: 0.9835\n",
            "Epoch 11/20\n",
            "212096/238103 [=========================>....] - ETA: 2s - loss: 0.0379 - acc: 0.9898"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 123us/step - loss: 0.0385 - acc: 0.9896 - val_loss: 0.0613 - val_acc: 0.9848\n",
            "Epoch 12/20\n",
            "213248/238103 [=========================>....] - ETA: 2s - loss: 0.0358 - acc: 0.9900"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 123us/step - loss: 0.0360 - acc: 0.9900 - val_loss: 0.0618 - val_acc: 0.9852\n",
            "Epoch 13/20\n",
            "213504/238103 [=========================>....] - ETA: 2s - loss: 0.0339 - acc: 0.9908"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 122us/step - loss: 0.0342 - acc: 0.9907 - val_loss: 0.0601 - val_acc: 0.9856\n",
            "Epoch 14/20\n",
            "213248/238103 [=========================>....] - ETA: 2s - loss: 0.0317 - acc: 0.9915"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 123us/step - loss: 0.0322 - acc: 0.9912 - val_loss: 0.0622 - val_acc: 0.9849\n",
            "Epoch 15/20\n",
            "211456/238103 [=========================>....] - ETA: 3s - loss: 0.0298 - acc: 0.9917"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 124us/step - loss: 0.0302 - acc: 0.9917 - val_loss: 0.0595 - val_acc: 0.9865\n",
            "Epoch 16/20\n",
            "211456/238103 [=========================>....] - ETA: 3s - loss: 0.0287 - acc: 0.9922"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 123us/step - loss: 0.0287 - acc: 0.9921 - val_loss: 0.0600 - val_acc: 0.9867\n",
            "Epoch 17/20\n",
            "211456/238103 [=========================>....] - ETA: 3s - loss: 0.0265 - acc: 0.9924"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 30s 124us/step - loss: 0.0278 - acc: 0.9922 - val_loss: 0.0626 - val_acc: 0.9866\n",
            "Epoch 18/20\n",
            "211584/238103 [=========================>....] - ETA: 3s - loss: 0.0252 - acc: 0.9930"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 29s 124us/step - loss: 0.0260 - acc: 0.9929 - val_loss: 0.0654 - val_acc: 0.9862\n",
            "Epoch 19/20\n",
            "211200/238103 [=========================>....] - ETA: 3s - loss: 0.0249 - acc: 0.9931"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 30s 124us/step - loss: 0.0252 - acc: 0.9931 - val_loss: 0.0594 - val_acc: 0.9878\n",
            "Epoch 20/20\n",
            "211712/238103 [=========================>....] - ETA: 3s - loss: 0.0242 - acc: 0.9934"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 30s 124us/step - loss: 0.0245 - acc: 0.9933 - val_loss: 0.0650 - val_acc: 0.9860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1eoesp2_mrSX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1159
        },
        "outputId": "e27499bc-22d0-4308-e4d7-00a087786047",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528826375891,
          "user_tz": 420,
          "elapsed": 1326761,
          "user": {
            "displayName": "Winston Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104495917744035597997"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mod3 = model3()\n",
        "mod3.summary()\n",
        "mod3.fit(x=X_train,\n",
        "          y=Y_train,\n",
        "          epochs=epochs, batch_size=128,verbose=1, validation_data=(X_valid, Y_valid))\n",
        "models.append(mod3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_1 (Batch (None, 28, 28, 1)         4         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 28, 28, 64)        51264     \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               6422656   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 26)                3354      \n",
            "=================================================================\n",
            "Total params: 6,478,238\n",
            "Trainable params: 6,478,172\n",
            "Non-trainable params: 66\n",
            "_________________________________________________________________\n",
            "Train on 238103 samples, validate on 59526 samples\n",
            "Epoch 1/20\n",
            " 13440/238103 [>.............................] - ETA: 1:09 - loss: 1.1199 - acc: 0.7520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 67s 282us/step - loss: 0.2360 - acc: 0.9404 - val_loss: 0.1313 - val_acc: 0.9673\n",
            "Epoch 2/20\n",
            " 19584/238103 [=>............................] - ETA: 56s - loss: 0.1022 - acc: 0.9727"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 67s 280us/step - loss: 0.0994 - acc: 0.9731 - val_loss: 0.0849 - val_acc: 0.9778\n",
            "Epoch 3/20\n",
            " 22400/238103 [=>............................] - ETA: 56s - loss: 0.0639 - acc: 0.9820"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 67s 280us/step - loss: 0.0739 - acc: 0.9795 - val_loss: 0.0845 - val_acc: 0.9775\n",
            "Epoch 4/20\n",
            " 23936/238103 [==>...........................] - ETA: 55s - loss: 0.0491 - acc: 0.9862"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 279us/step - loss: 0.0603 - acc: 0.9830 - val_loss: 0.0752 - val_acc: 0.9804\n",
            "Epoch 5/20\n",
            " 23424/238103 [=>............................] - ETA: 55s - loss: 0.0401 - acc: 0.9883"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 277us/step - loss: 0.0488 - acc: 0.9861 - val_loss: 0.0812 - val_acc: 0.9797\n",
            "Epoch 6/20\n",
            " 24704/238103 [==>...........................] - ETA: 55s - loss: 0.0332 - acc: 0.9901"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 277us/step - loss: 0.0411 - acc: 0.9881 - val_loss: 0.0725 - val_acc: 0.9824\n",
            "Epoch 7/20\n",
            " 24448/238103 [==>...........................] - ETA: 55s - loss: 0.0295 - acc: 0.9908"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 278us/step - loss: 0.0342 - acc: 0.9905 - val_loss: 0.0742 - val_acc: 0.9836\n",
            "Epoch 8/20\n",
            " 24960/238103 [==>...........................] - ETA: 54s - loss: 0.0188 - acc: 0.9944"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 278us/step - loss: 0.0298 - acc: 0.9917 - val_loss: 0.0745 - val_acc: 0.9844\n",
            "Epoch 9/20\n",
            " 21120/238103 [=>............................] - ETA: 56s - loss: 0.0256 - acc: 0.9936"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 278us/step - loss: 0.0275 - acc: 0.9925 - val_loss: 0.0887 - val_acc: 0.9833\n",
            "Epoch 10/20\n",
            " 22400/238103 [=>............................] - ETA: 55s - loss: 0.0285 - acc: 0.9928\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 278us/step - loss: 0.0243 - acc: 0.9935 - val_loss: 0.0826 - val_acc: 0.9844\n",
            "Epoch 11/20\n",
            " 18816/238103 [=>............................] - ETA: 57s - loss: 0.0193 - acc: 0.9945"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 277us/step - loss: 0.0221 - acc: 0.9944 - val_loss: 0.0898 - val_acc: 0.9858\n",
            "Epoch 12/20\n",
            " 22656/238103 [=>............................] - ETA: 55s - loss: 0.0275 - acc: 0.9936"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 277us/step - loss: 0.0228 - acc: 0.9944 - val_loss: 0.0787 - val_acc: 0.9875\n",
            "Epoch 13/20\n",
            " 24704/238103 [==>...........................] - ETA: 55s - loss: 0.0180 - acc: 0.9960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 278us/step - loss: 0.0210 - acc: 0.9948 - val_loss: 0.0850 - val_acc: 0.9868\n",
            "Epoch 14/20\n",
            " 21888/238103 [=>............................] - ETA: 56s - loss: 0.0142 - acc: 0.9967"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 278us/step - loss: 0.0208 - acc: 0.9952 - val_loss: 0.0793 - val_acc: 0.9884\n",
            "Epoch 15/20\n",
            " 23168/238103 [=>............................] - ETA: 55s - loss: 0.0132 - acc: 0.9974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 277us/step - loss: 0.0188 - acc: 0.9957 - val_loss: 0.0816 - val_acc: 0.9873\n",
            "Epoch 16/20\n",
            " 22912/238103 [=>............................] - ETA: 55s - loss: 0.0100 - acc: 0.9976"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 277us/step - loss: 0.0187 - acc: 0.9958 - val_loss: 0.0937 - val_acc: 0.9858\n",
            "Epoch 17/20\n",
            " 22400/238103 [=>............................] - ETA: 56s - loss: 0.0175 - acc: 0.9958"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 278us/step - loss: 0.0187 - acc: 0.9959 - val_loss: 0.1029 - val_acc: 0.9850\n",
            "Epoch 18/20\n",
            " 22656/238103 [=>............................] - ETA: 56s - loss: 0.0226 - acc: 0.9955"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 66s 279us/step - loss: 0.0174 - acc: 0.9964 - val_loss: 0.1062 - val_acc: 0.9852\n",
            "Epoch 19/20\n",
            " 22144/238103 [=>............................] - ETA: 56s - loss: 0.0141 - acc: 0.9972"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 67s 280us/step - loss: 0.0190 - acc: 0.9961 - val_loss: 0.0895 - val_acc: 0.9881\n",
            "Epoch 20/20\n",
            " 20352/238103 [=>............................] - ETA: 56s - loss: 0.0192 - acc: 0.9966"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "238103/238103 [==============================] - 67s 279us/step - loss: 0.0171 - acc: 0.9964 - val_loss: 0.1070 - val_acc: 0.9863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WgHtk_6UmvG0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ensemble"
      ]
    },
    {
      "metadata": {
        "id": "uxv43q_Jmwqo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d33257f6-6be0-4b44-8be9-6b96fcb10787",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528826400984,
          "user_tz": 420,
          "elapsed": 25068,
          "user": {
            "displayName": "Winston Lan",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104495917744035597997"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "preds = tf.argmax(np.mean([mod.predict(X_test) for mod in models], axis=0),1)\n",
        "Y_pred = tf.Session().run(preds)\n",
        "incorrect = 0\n",
        "for i in range(len(Y_pred)):\n",
        "  if Y_pred[i] != Y_test[i]:\n",
        "    incorrect += 1\n",
        "print(\"Accuracy:\", 1.0 * (len(Y_pred)-incorrect) / len(Y_pred) )"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.991801956778841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Iv5dEvbIlgCq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
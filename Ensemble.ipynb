{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aApvxtKxRPwm"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0ff3b1037967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrive\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleDrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Code to read csv file into colaboratory:# Code  \n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "#2. Get the file\n",
    "downloaded = drive.CreateFile({'id':'10Xf2Xv_pfnIycH2HpNZR3SwWHiHdrqzX'}) # replace the id with id of file you want to access\n",
    "downloaded.GetContentFile('handwritten.csv')  \n",
    "\n",
    "#3. Read file as panda dataframe\n",
    "import pandas as pd\n",
    "data = pd.read_csv('handwritten.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wNge0YaORXfP"
   },
   "outputs": [],
   "source": [
    "!pip install -q keras\n",
    "!pip install -q numpy\n",
    "!pip install -q sklearn\n",
    "!pip install -q matplotlib\n",
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9glOPQgnRYRU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ryan/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZcbVL0YBRe2Y"
   },
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27654,
     "status": "ok",
     "timestamp": 1528766535765,
     "user": {
      "displayName": "YeeJay Ng",
      "photoUrl": "//lh6.googleusercontent.com/-RF8GVunHxUU/AAAAAAAAAAI/AAAAAAAAAVY/-iRhkzqefyU/s50-c-k-no/photo.jpg",
      "userId": "113615214030775264970"
     },
     "user_tz": 420
    },
    "id": "Qmg3cqTvRgjd",
    "outputId": "8bee5e6c-2452-4314-e65a-ed6c7e574e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (297629, 784) (297629,)\n",
      "Test (74408, 784) (74408,)\n"
     ]
    }
   ],
   "source": [
    "# Get the data from the csv file\n",
    "data = data.values\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Split the data into X, Y, and parition the values into the training and test splits\n",
    "# Reshape X to be in the shape (N, 28, 28)\n",
    "X, Y = data[:,1:], data[:,0]\n",
    "# X = X.reshape(X.shape[0], 28, 28)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print(\"Train {} {}\".format(X_train.shape, Y_train.shape))\n",
    "print(\"Test {} {}\".format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JE3jBErRm9q"
   },
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1528766536392,
     "user": {
      "displayName": "YeeJay Ng",
      "photoUrl": "//lh6.googleusercontent.com/-RF8GVunHxUU/AAAAAAAAAAI/AAAAAAAAAVY/-iRhkzqefyU/s50-c-k-no/photo.jpg",
      "userId": "113615214030775264970"
     },
     "user_tz": 420
    },
    "id": "NwCbFYbQRlSO",
    "outputId": "721e40a7-7ed2-40a7-df81-99c1cd58005c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  26\n",
      "Output classes :  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(Y_train)\n",
    "n_classes = len(classes)\n",
    "print('Total number of outputs : ', n_classes)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pJXDA8nDjIau"
   },
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "classes = np.unique(Y_train)\n",
    "num_classes = len(classes)\n",
    "\n",
    "X_train = X_train.reshape(-1, img_size, img_size, 1)\n",
    "X_test = X_test.reshape(-1, img_size, img_size, 1)\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cAnZg7iRqkD"
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0o5zJFqHRsY1"
   },
   "outputs": [],
   "source": [
    "mean_image = np.mean(X_train, axis=0).astype(np.int64)\n",
    "X_train = (X_train - mean_image)/255\n",
    "X_test = (X_test - mean_image)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2430,
     "status": "ok",
     "timestamp": 1528766541907,
     "user": {
      "displayName": "YeeJay Ng",
      "photoUrl": "//lh6.googleusercontent.com/-RF8GVunHxUU/AAAAAAAAAAI/AAAAAAAAAVY/-iRhkzqefyU/s50-c-k-no/photo.jpg",
      "userId": "113615214030775264970"
     },
     "user_tz": 420
    },
    "id": "EZumZB90RwQ4",
    "outputId": "310d2d9b-d933-4941-9b7b-640c2e8bf8d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Label: 2\n",
      "One Hot Label: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "Y_train_onehot = to_categorical(Y_train)\n",
    "Y_test_onehot = to_categorical(Y_test)\n",
    "print(\"Original Label: {}\".format(Y_train[0]))\n",
    "print(\"One Hot Label: {}\".format(Y_train_onehot[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1132,
     "status": "ok",
     "timestamp": 1528766543091,
     "user": {
      "displayName": "YeeJay Ng",
      "photoUrl": "//lh6.googleusercontent.com/-RF8GVunHxUU/AAAAAAAAAAI/AAAAAAAAAVY/-iRhkzqefyU/s50-c-k-no/photo.jpg",
      "userId": "113615214030775264970"
     },
     "user_tz": 420
    },
    "id": "CE4szLSER3bm",
    "outputId": "a29c8f44-76f1-4a3b-9d21-16e32c5dc955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (238103, 28, 28, 1) (238103, 26)\n",
      "Valid: (59526, 28, 28, 1) (59526, 26)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train_onehot, test_size=0.2)\n",
    "\n",
    "print(\"Train: {} {}\".format(X_train.shape, Y_train.shape))\n",
    "print(\"Valid: {} {}\".format(X_valid.shape, Y_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYho84e7evEn"
   },
   "source": [
    "# Keras Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_X_vsIL-ew0b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.layers import LeakyReLU, ELU\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import InputLayer, Input\n",
    "from tensorflow.python.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras.losses import mean_absolute_error\n",
    "\n",
    "#Add whatever you need here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-krwZ9khFEO"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJHUv_1ge9Bq"
   },
   "source": [
    "### [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MNgdmXdxe-5y"
   },
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model = Sequential()\n",
    "    '''\n",
    "    initializer: he_normal\n",
    "    A more recent paper on this topic, Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification by He et al., \n",
    "    derives an initialization specifically for ReLU neurons, reaching the conclusion that the variance of neurons \n",
    "    in the network should be 2.0/n. This gives the initialization w = np.random.randn(n) * sqrt(2.0/n), \n",
    "    and is the current recommendation for use in practice in the specific case of neural networks with ReLU neurons.\n",
    "    '''\n",
    "    #convolutional layer\n",
    "    model.add(Conv2D(kernel_size=7, strides=1, filters=16, padding='same',\n",
    "                     activation='linear', name='layer_conv1', input_shape=img_shape_full))\n",
    "    #reLU activation\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #Pooling Layer\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    #Fully-Connected Layer with 128 outputs Adding this in improved scores\n",
    "    model.add(Dense(128, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #Fully-Connected Layer with Softmax\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    '''\n",
    "    For multiclass classification problems like MNIST, cross entropy is typically used as the loss metric\n",
    "    '''\n",
    "    model.compile(optimizer=Adam(lr=1e-3),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "# Insert model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXEGJeOzfB8o"
   },
   "source": [
    "### [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YNidiKw6fGro"
   },
   "outputs": [],
   "source": [
    "def model2():\n",
    "  optimizer = Adam(lr=1e-3)\n",
    "\n",
    "  model = Sequential()\n",
    "\n",
    "  #conv\n",
    "  #keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, \n",
    "      #dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', \n",
    "      #bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \n",
    "      #activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "  model.add(Conv2D(filters=16, kernel_size=8, strides = 1, padding='same', activation='linear',\n",
    "                   bias_initializer='zeros', input_shape=(img_size,img_size,1)))\n",
    "\n",
    "  #ReLu\n",
    "  model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "  #conv2\n",
    "  model.add(Conv2D(filters=16, kernel_size=8, strides = 2, padding='same', activation='linear',\n",
    "                   bias_initializer='zeros', input_shape=(img_size,img_size,1)))\n",
    "\n",
    "  #ReLu\n",
    "  model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "  #MaxPool\n",
    "  #keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)\n",
    "  model.add(MaxPooling2D(strides=2, padding='same'))\n",
    "\n",
    "  #Affine\n",
    "  model.add(Flatten())\n",
    "\n",
    "  #keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', \n",
    "      #bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \n",
    "      #activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "  #model.add(Dense(56, activation=\"relu\"))\n",
    "\n",
    "  model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a13Nl1_pfLaO"
   },
   "source": [
    "### [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aQoy4r-CfWPi"
   },
   "outputs": [],
   "source": [
    "def model3():\n",
    "  pass\n",
    "# Insert model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJ6juMoVhLNr"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mbcpr6eknB0n"
   },
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pBziSjFammXN"
   },
   "outputs": [],
   "source": [
    "mod1 = model1()\n",
    "mod1.fit(x=X_train,\n",
    "          y=Y_train,\n",
    "          epochs=5, batch_size=128,verbose=1, validation_data=(X_valid, Y_valid))\n",
    "models.append(mod1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62183,
     "status": "ok",
     "timestamp": 1528767925348,
     "user": {
      "displayName": "YeeJay Ng",
      "photoUrl": "//lh6.googleusercontent.com/-RF8GVunHxUU/AAAAAAAAAAI/AAAAAAAAAVY/-iRhkzqefyU/s50-c-k-no/photo.jpg",
      "userId": "113615214030775264970"
     },
     "user_tz": 420
    },
    "id": "9lanntfjhOxR",
    "outputId": "6ecd94ed-4fa1-41d2-df2b-955ed8a25a95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238103 samples, validate on 59526 samples\n",
      "Epoch 1/2\n",
      "238103/238103 [==============================] - 31s 129us/step - loss: 0.2482 - acc: 0.9320 - val_loss: 0.1222 - val_acc: 0.9683\n",
      "Epoch 2/2\n",
      " 49920/238103 [=====>........................] - ETA: 22s - loss: 0.1141 - acc: 0.9701238103/238103 [==============================] - 30s 127us/step - loss: 0.1060 - acc: 0.9717 - val_loss: 0.1173 - val_acc: 0.9691\n"
     ]
    }
   ],
   "source": [
    "#model2().summary()\n",
    "mod2 = model2()\n",
    "mod2.fit(x=X_train,\n",
    "          y=Y_train,\n",
    "          epochs=2, batch_size=128,verbose=1, validation_data=(X_valid, Y_valid))\n",
    "models.append(mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1eoesp2_mrSX"
   },
   "outputs": [],
   "source": [
    "#mod3 = model3()\n",
    "#mod3.fit(x=X_train,\n",
    "#           y=Y_train,\n",
    "#           epochs=5, batch_size=128,verbose=1, validation_data=(X_valid, Y_valid))\n",
    "#models.append(mod3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WgHtk_6UmvG0"
   },
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5804,
     "status": "ok",
     "timestamp": 1528770414434,
     "user": {
      "displayName": "YeeJay Ng",
      "photoUrl": "//lh6.googleusercontent.com/-RF8GVunHxUU/AAAAAAAAAAI/AAAAAAAAAVY/-iRhkzqefyU/s50-c-k-no/photo.jpg",
      "userId": "113615214030775264970"
     },
     "user_tz": 420
    },
    "id": "uxv43q_Jmwqo",
    "outputId": "00749e0c-b2ff-4631-ff20-dcc58c42a149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74408, 26)\n",
      "[14 17 18 ...  3 17 19]\n",
      "[14 17 18 ...  3 17 19]\n",
      "Accuracy: 0.9698150736479948\n"
     ]
    }
   ],
   "source": [
    "# print(mod2.predict(X_test))\n",
    "# mod2Pred = mod2.predict(X_test)\n",
    "# type(mod2Pred)\n",
    "print(mod2Pred.shape)\n",
    "preds = tf.argmax(np.mean([mod.predict(X_test) for mod in models], axis=0),1)\n",
    "# print(preds.shape)\n",
    "# print(preds)\n",
    "# Y_pred = tf.Session().run(preds)\n",
    "print(Y_pred)\n",
    "print(Y_test)\n",
    "\n",
    "incorrect = 0\n",
    "for i in range(len(Y_pred)):\n",
    "  if Y_pred[i] != Y_test[i]:\n",
    "    incorrect += 1\n",
    "print(\"Accuracy:\", 1.0 * (len(Y_pred)-incorrect) / len(Y_pred) )\n",
    "\n",
    "#print(mean_absolute_error(Y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Ensemble.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

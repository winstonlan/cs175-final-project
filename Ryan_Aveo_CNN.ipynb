{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ryan/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will implement [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM] and write script to print accuracy of models on test and train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/handwritten_data_785.csv\", encoding = \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data = data.values\n",
    "np.random.shuffle(data)\n",
    "X, y = data[:,1:], data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297629, 784)\n",
      "(74408, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#images are 28x28\n",
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "num_channels = 1\n",
    "num_classes = 26\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_size, img_size, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_size, img_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_image = np.mean(X_train, axis=0).astype(np.int64)\n",
    "X_train = (X_train - mean_image)/255\n",
    "X_test = (X_test - mean_image)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_biases(length):\n",
    "    return tf.Variable(tf.constant(0.01, shape=[length]))\n",
    "'''\n",
    "One problem is that the distribution of the outputs from a randomly initialized \n",
    "neuron has a variance that grows with the number of inputs. It turns out that we can normalize the variance \n",
    "of each neuron’s output to 1 by scaling its weight vector by the square root of its fan-in (i.e. its number of inputs).\n",
    "That is, the recommended heuristic is to initialize each neuron’s weight vector as: w = np.random.randn(n) / sqrt(n), \n",
    "where n is the number of its inputs. This ensures that all neurons in the network initially have approximately the \n",
    "same output distribution and empirically improves the rate of convergence.\n",
    "'''\n",
    "# xavier_initializer is 2/sqrt(n) when uniform=False\n",
    "def create_weights(shape):\n",
    "    initializer = tf.contrib.layers.xavier_initializer(uniform=False)\n",
    "    return tf.Variable(initializer(shape))\n",
    "\n",
    "def conv_layer(input, input_channels, filter_size, num_filters, x_stride=1, y_stride=1):\n",
    "    '''\n",
    "    input (4d Tensor):\n",
    "        -Image number.\n",
    "        -Y-axis of each image.\n",
    "        -X-axis of each image.\n",
    "        -Channels of each image.\n",
    "    input_channels: number of channels in the input\n",
    "    filter_size: window size of filter (ex: 5x5)\n",
    "    num_filters: number of filters to use\n",
    "    x_stride: amount to move filter over on x axis\n",
    "    y_stride: amount to move filter over on y axis\n",
    "        ex: strides=[1, 2, 2, 1] would mean that the filter\n",
    "        is moved 2 pixels across the x- and y-axis of the image\n",
    "    use_batchnorm: whether or not to use batch normalization on this layer\n",
    "    \n",
    "    initializes weights\n",
    "    '''\n",
    "    weights_shape = [filter_size, filter_size, input_channels, num_filters]\n",
    "    weights = create_weights(weights_shape)\n",
    "    \n",
    "    biases = create_biases(num_filters)\n",
    "    \n",
    "    #create layer\n",
    "    layer = tf.nn.conv2d(input, weights, strides=[1,x_stride,y_stride,1], padding='VALID') + biases\n",
    "    \n",
    "    # ** maybe split pooling and batch_norm??\n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    layer = tf.nn.max_pool(layer, ksize=[1,2,2,1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    return layer, weights\n",
    "\n",
    "def flatten(layer):\n",
    "    '''\n",
    "    flattens a layer to feed it as input to a fully connected layer\n",
    "    '''\n",
    "    shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    num_features = shape[1:4].num_elements()\n",
    "    \n",
    "    # If one component of shape is the special value -1, \n",
    "    # the size of that dimension is computed so that the total size remains constant.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features\n",
    "\n",
    "def new_fc_layer(input, num_inputs, num_outputs):\n",
    "    '''\n",
    "    fully_connected_layer\n",
    "    '''\n",
    "    weights = create_weights((num_inputs, num_outputs))\n",
    "    biases = create_biases(num_outputs)\n",
    "    \n",
    "    return tf.matmul(input, weights) + biases\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: One layer of each ([conv-relu-pool] -> [affine]-> [softmax or SVM])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, deeper networks is always better, at the cost of more data and increased complexity of learning.\n",
    "Minibatch size is usually set of few hundreds. \n",
    "You should initially use fewer filters and gradually increase and monitor the error rate to see how it is varying.\n",
    "Very small filter sizes will capture very fine details of the image. On the other hand having a bigger filter size \n",
    "will leave out minute details in the image.\n",
    "https://www.quora.com/How-can-I-decide-the-kernel-size-output-maps-and-layers-of-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)\n",
    "\n",
    "conv_layer1, weights_conv_layer1 = conv_layer(X,num_channels,filter_size=7,num_filters=16)\n",
    "conv_layer_flat,num_features = flatten(conv_layer1)\n",
    "fc_layer = new_fc_layer(conv_layer_flat, num_features, num_classes)\n",
    "\n",
    "y_pred = tf.nn.softmax(fc_layer)\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ryan/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import InputLayer, Input\n",
    "from tensorflow.python.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will implement [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM] and write script to print accuracy of models on test and train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/handwritten_data_785.csv\", encoding = \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data = data.values\n",
    "np.random.shuffle(data)\n",
    "X, y = data[:,1:], data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (297629, 784) (297629,)\n",
      "Valid: (59526, 784) (59526,)\n",
      "Test: (74408, 784) (74408,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(\"Train: {} {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Valid: {} {}\".format(X_valid.shape, y_valid.shape))\n",
    "print(\"Test: {} {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_image = np.mean(X_train, axis=0).astype(np.int64)\n",
    "X_train = (X_train - mean_image)/255\n",
    "X_test = (X_test - mean_image)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_one_hot = to_categorical(y_train)\n",
    "test_Y_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297629, 784)\n",
      "(74408, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#images are 28x28\n",
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Tuple with height, width and depth used to reshape arrays.\n",
    "# This is used for reshaping in Keras.\n",
    "img_shape_full = (img_size, img_size, 1)\n",
    "\n",
    "num_channels = 1\n",
    "num_classes = 26\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_size, img_size, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_size, img_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: One layer of each ([conv-relu-pool] -> [affine]-> [softmax or SVM])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, deeper networks is always better, at the cost of more data and increased complexity of learning.\n",
    "Minibatch size is usually set of few hundreds. \n",
    "You should initially use fewer filters and gradually increase and monitor the error rate to see how it is varying.\n",
    "Very small filter sizes will capture very fine details of the image. On the other hand having a bigger filter size \n",
    "will leave out minute details in the image.\n",
    "https://www.quora.com/How-can-I-decide-the-kernel-size-output-maps-and-layers-of-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.layers import LeakyReLU\n",
    "from tensorflow.python.keras import initializers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Function to create model, required for KerasClassifier\n",
    "    \n",
    "    We pass this function name to the KerasClassifier class by the build_fn argument. \n",
    "    We also pass in additional arguments of epochs and batch_size. \n",
    "    These are automatically bundled up and passed on to the fit() function which is called \n",
    "    internally by the KerasClassifier class.\n",
    "    \n",
    "    https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/\n",
    "'''\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    '''\n",
    "    initializer: he_normal\n",
    "    A more recent paper on this topic, Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification by He et al., \n",
    "    derives an initialization specifically for ReLU neurons, reaching the conclusion that the variance of neurons \n",
    "    in the network should be 2.0/n. This gives the initialization w = np.random.randn(n) * sqrt(2.0/n), \n",
    "    and is the current recommendation for use in practice in the specific case of neural networks with ReLU neurons.\n",
    "    '''\n",
    "    #convolutional layer\n",
    "    model.add(Conv2D(kernel_size=7, strides=1, filters=16, padding='same',\n",
    "                     activation='linear', name='layer_conv1', input_shape=img_shape_full))\n",
    "    #reLU activation\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #Pooling Layer\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    #Fully-Connected Layer with 128 outputs Adding this in improved scores\n",
    "    model.add(Dense(128, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #Fully-Connected Layer with Softmax\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    '''\n",
    "    For multiclass classification problems like MNIST, cross entropy is typically used as the loss metric\n",
    "    '''\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=3, batch_size=150, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "238093/238093 [==============================] - 260s 1ms/step - loss: 0.1535 - acc: 0.9582\n",
      "Epoch 2/3\n",
      "238093/238093 [==============================] - 341s 1ms/step - loss: 0.0721 - acc: 0.9807\n",
      "Epoch 3/3\n",
      "238093/238093 [==============================] - 270s 1ms/step - loss: 0.0569 - acc: 0.9846\n",
      "59536/59536 [==============================] - 23s 394us/step\n",
      "Epoch 1/3\n",
      "238098/238098 [==============================] - 242s 1ms/step - loss: 0.1502 - acc: 0.9589\n",
      "Epoch 2/3\n",
      "238098/238098 [==============================] - 206s 865us/step - loss: 0.0706 - acc: 0.9812\n",
      "Epoch 3/3\n",
      "238098/238098 [==============================] - 187s 785us/step - loss: 0.0544 - acc: 0.9852\n",
      "59531/59531 [==============================] - 18s 301us/step\n",
      "Epoch 1/3\n",
      "238105/238105 [==============================] - 180s 758us/step - loss: 0.1482 - acc: 0.9596\n",
      "Epoch 2/3\n",
      "238105/238105 [==============================] - 206s 866us/step - loss: 0.0704 - acc: 0.9810\n",
      "Epoch 3/3\n",
      "238105/238105 [==============================] - 208s 875us/step - loss: 0.0545 - acc: 0.9856\n",
      "59524/59524 [==============================] - 22s 370us/step\n",
      "Epoch 1/3\n",
      "238108/238108 [==============================] - 217s 913us/step - loss: 0.1521 - acc: 0.9582\n",
      "Epoch 2/3\n",
      "238108/238108 [==============================] - 233s 979us/step - loss: 0.0709 - acc: 0.9812\n",
      "Epoch 3/3\n",
      "238108/238108 [==============================] - 209s 877us/step - loss: 0.0545 - acc: 0.9855\n",
      "59521/59521 [==============================] - 24s 409us/step\n",
      "Epoch 1/3\n",
      "238112/238112 [==============================] - 198s 832us/step - loss: 0.1549 - acc: 0.9579\n",
      "Epoch 2/3\n",
      "238112/238112 [==============================] - 292s 1ms/step - loss: 0.0729 - acc: 0.9806\n",
      "Epoch 3/3\n",
      "238112/238112 [==============================] - 296s 1ms/step - loss: 0.0566 - acc: 0.9845\n",
      "59517/59517 [==============================] - 29s 482us/step\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Must use non-one-hot data:\n",
    "        \n",
    "    keras.utils.to_categorical produces a one-hot encoded class vector, i\n",
    "    .e. the multilabel-indicator mentioned in the error message. \n",
    "    StratifiedKFold is not designed to work with such input;\n",
    "    from:\n",
    "    https://stackoverflow.com/questions/48508036/sklearn-stratifiedkfold-valueerror-supported-target-types-are-binary-mul\n",
    "'''\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "model_accuracy = results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Cross-Validation Accuracy =  0.9817255074409299\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Cross-Validation Accuracy = \", model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>without he_normal weights initialization and 0.01 biases initialization:</strong>\n",
    "\n",
    "Train on 297629 samples, validate on 74408 samples\n",
    "\n",
    "Epoch 1/1\n",
    "loss: 0.1502 - acc: 0.9591 \n",
    "\n",
    "val_loss: 0.0927 - val_acc: 0.9762\n",
    "\n",
    "<strong>using he_normal weight initialization and 0.01 biases initialization actually decreased accuracy by 0.0014</strong>\n",
    "\n",
    "Train on 297629 samples, validate on 74408 samples\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "loss: 0.1835 - acc: 0.9494 - \n",
    "\n",
    "val_loss: 0.0963 - val_acc: 0.9748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = model.evaluate(test_X, test_Y_one_hot, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_train.history['acc']\n",
    "val_accuracy = model_train.history['val_acc']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
